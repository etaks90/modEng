{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and for initial data analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "def get_base_data(fp):\n",
    "\n",
    "    df = pd.read_excel(fp)\n",
    "    \n",
    "    def count_previous_attempts(row, minutes_window=5):\n",
    "        same_amount = df['amount'] == row['amount']\n",
    "        same_country = df['country'] == row['country']\n",
    "        time_window = (df['tmsp'] >= (row['tmsp'] - timedelta(minutes=minutes_window))) & (df['tmsp'] < row['tmsp'])\n",
    "        return df[same_amount & same_country & time_window].shape[0]\n",
    "    df[\"hour_of_day\"] = df[\"tmsp\"].dt.hour\n",
    "    df[\"day_of_week\"] = df[\"tmsp\"].dt.dayofweek\n",
    "    df['previous_attempts'] = df.apply(count_previous_attempts, axis=1)\n",
    "\n",
    "    df.to_pickle(\"df2.pkl\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_base_data_from_pickle(fp):\n",
    "    return pd.read_pickle(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df and calculate additional fields - takes long\n",
    "#df = get_base_data(r\"G:\\My Drive\\masterDataScience\\ModelEngineering\\use_case_1\\PSP_Jan_Feb_2019.xlsx\")\n",
    "\n",
    "# load df with all additional fields\n",
    "df = get_base_data_from_pickle(r\"in\\df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for categorical columns\n",
    "\n",
    "nrows, ncols = 3, 2\n",
    "font_size = 20\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 8))\n",
    "\n",
    "axes = axes.flatten()\n",
    "axes = axes[:5]\n",
    "\n",
    "df_str = df.astype(str)\n",
    "\n",
    "for i, column in enumerate(df_str[[\"country\", \"success\", \"PSP\", \"3D_secured\", \"card\"]].columns):\n",
    "    if 1 == 1:\n",
    "        ax = axes[i]\n",
    "        ax.hist(df_str[column])\n",
    "        ax.set_title(f'Histogram of {column}', fontsize=font_size)\n",
    "        ax.set_xlabel(column, fontsize=font_size)\n",
    "        ax.set_ylabel('Frequency', fontsize=font_size)\n",
    "        ax.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "    print(column)\n",
    "    print(df_str[column].unique())\n",
    "\n",
    "for i in range(len(df_str.columns), (nrows * ncols)-1):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kernel densities for numerical columns\n",
    "\n",
    "nrows, ncols = 2, 1\n",
    "font_size = 20\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 8))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "df['numeric_tmsp'] = (df['tmsp'] - df['tmsp'].min()).dt.total_seconds()\n",
    "for i, column in enumerate(df[[\"amount\", \"numeric_tmsp\"]].columns):\n",
    "    if 1 == 1:\n",
    "        ax = axes[i]\n",
    "        kde = gaussian_kde(df[column])\n",
    "        x = np.linspace(min(df[column]), max(df[column]), 100)\n",
    "        y = kde(x)\n",
    "        ax.plot(x, y, linewidth=2)  # Plot the KDE\n",
    "        ax.set_title(f'Kernel Density Estimation of {column}', fontsize=font_size)  # Set title font size\n",
    "        ax.set_xlabel(column, fontsize=font_size)  # Set x-axis label font size\n",
    "        ax.set_ylabel('Density', fontsize=font_size)  # Set y-axis label font size\n",
    "        ax.tick_params(axis='both', labelsize=font_size)\n",
    "    print(column)\n",
    "    if column == \"amount\":\n",
    "        print(min(df[column]))\n",
    "        print(max(df[column]))\n",
    "        print(np.std(df[column]))\n",
    "    else:\n",
    "        print(min(df[\"tmsp\"]))\n",
    "        print(max(df[\"tmsp\"]))\n",
    "\n",
    "for i in range(len(df_str.columns), nrows * ncols):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram to show impact of PSP\n",
    "\n",
    "def plot_hist_per_psp(df, col, ax, font_size = 20):\n",
    "    grouped = df.groupby([col, 'PSP'])['success'].mean() * 100\n",
    "    pivot_table = grouped.unstack(level=1)\n",
    "\n",
    "    pivot_table.plot(kind='bar', stacked=False, ax=ax)\n",
    "    ax.set_title(f'Percentage of Successful Attempts by {col} and PSP', fontsize=font_size)\n",
    "    ax.set_xlabel(col, fontsize=font_size)\n",
    "    ax.set_ylabel('Success Percentage', fontsize=font_size)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=font_size)\n",
    "    ax.legend(title='PSP', loc='upper right')\n",
    "    ax.tick_params(axis='both', labelsize=20)\n",
    "\n",
    "# Create a single figure with subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 12))\n",
    "columns = [\"country\", \"day_of_week\"]\n",
    "\n",
    "# Flatten the axes array to access each subplot\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    plot_hist_per_psp(df, col, axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for additional field \"previous_attempts\"\n",
    "\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax1 = plt.gca()\n",
    "plt.hist(df['previous_attempts'], edgecolor='black', alpha=0.9, color='green') \n",
    "plt.xlabel('# previous_attempts', fontsize=font_size)\n",
    "plt.ylabel('Frequency', fontsize=font_size, color='green')\n",
    "\n",
    "plt.xticks(fontsize=font_size)\n",
    "plt.yticks(fontsize=font_size, color='green') \n",
    "\n",
    "success_rate = df.groupby('previous_attempts')['success'].mean()\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "ax2.bar(success_rate.index, success_rate.values, align='center', alpha=0.7, color='blue') \n",
    "ax2.set_ylabel('Success Rate', fontsize=font_size, color='blue') \n",
    "\n",
    "ax2.set_yticklabels(ax2.get_yticks(), fontsize=font_size, color='blue')  \n",
    "\n",
    "ax2.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "\n",
    "plt.title('Success Rate vs. Previous Attempts')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel density of amount for different PSPs\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def plot_kde_all(df, col):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    df_filtered = df[[col, 'PSP', 'success']]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for psp_value in df_filtered['PSP'].unique():\n",
    "        data_subset = df_filtered[df_filtered['PSP'] == psp_value]\n",
    "        sns.kdeplot(data_subset[col], label=f'PSP {psp_value}', shade=True)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Kernel Density\")\n",
    "    plt.title(f'Kernel Density Estimation of {col} by PSP')\n",
    "    plt.legend(title='PSP', loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "plot_kde_all(df, 'amount')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features and target\n",
    "\n",
    "num_cols = [\"amount\", \"previous_attempts\"]\n",
    "cat_cols = [\"country\", \"PSP\", \"3D_secured\", \"card\", \"day_of_week\"]\n",
    "target_col = \"success\"\n",
    "\n",
    "list_features = num_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "col_trans = ColumnTransformer([\n",
    "    ('num', MinMaxScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(drop='if_binary'), cat_cols)\n",
    "])\n",
    "\n",
    "df_transformed = col_trans.fit_transform(df[list_features])\n",
    "X = df_transformed[:, :]\n",
    "y = df[\"success\"]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=10)\n",
    "\n",
    "# oversampling is important, check difference!!\n",
    "# Apply oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# See the inital model performance\n",
    "clf = RandomForestClassifier(random_state=10)\n",
    "print(\"Random parameters\")\n",
    "print('Acc:', cross_val_score(clf, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='accuracy').mean())\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal parameters\n",
    "# Takes long!!\n",
    "if 1 == 2:\n",
    "    clf = GridSearchCV(RandomForestClassifier(random_state=10), param_grid=params, \n",
    "                    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=10), scoring='f1')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(clf.best_params_) # {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}\n",
    "    print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "clf = RandomForestClassifier(n_estimators=50,\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             random_state=11)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature importance\n",
    "feat_names_num = list(col_trans.transformers_[0][1].get_feature_names_out())\n",
    "feat_names_cat = list(col_trans.transformers_[1][1].get_feature_names_out())\n",
    "feature_names = feat_names_num + feat_names_cat\n",
    "df_importance = pd.DataFrame({'feature': feature_names, 'importance': clf.feature_importances_})\n",
    "df_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantify performance\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, ConfusionMatrixDisplay, recall_score, precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create a random classifier that makes random guesses\n",
    "random_classifier = DummyClassifier(strategy=\"uniform\", random_state=42)  # \"uniform\" strategy for random guessing\n",
    "\n",
    "# Fit the random classifier on the training data\n",
    "random_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and probabilities from your original classifier\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_proba = clf.predict_proba(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_proba = clf.predict_proba(X_test)\n",
    "\n",
    "# Predictions from the random classifier\n",
    "y_random_train_pred = random_classifier.predict(X_train)\n",
    "y_random_test_pred = random_classifier.predict(X_test)\n",
    "\n",
    "# Calculate and compare performance metrics\n",
    "print(\"Train Acc (Original):\", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "print(\"Train Acc (Random Guessing):\", accuracy_score(y_train, y_random_train_pred))\n",
    "\n",
    "# Similar comparisons for test data\n",
    "print(\"Test Acc (Original):\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(\"Test Acc (Random Guessing):\", accuracy_score(y_test, y_random_test_pred))\n",
    "\n",
    "# Confusion matrices for both classifiers (original and random)\n",
    "print(\"Confusion Matrix (Original) - Train:\")\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X_train, y_train)\n",
    "print(\"Confusion Matrix (Original) - Test:\")\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, normalize=\"all\")\n",
    "\n",
    "print(\"Confusion Matrix (Random Guessing) - Train:\")\n",
    "ConfusionMatrixDisplay.from_estimator(random_classifier, X_train, y_train)\n",
    "print(\"Confusion Matrix (Random Guessing) - Test:\")\n",
    "ConfusionMatrixDisplay.from_estimator(random_classifier, X_test, y_test, normalize=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of current implementation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "actual = y_test\n",
    "predicted = y_test.copy()\n",
    "predicted.loc[:] = 1\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "# Create a ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
    "\n",
    "print(\"Test Acc (Current):\", accuracy_score(actual, predicted))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([('transformer', col_trans),('classifier', clf)])\n",
    "\n",
    "joblib.dump(pipeline, r'in\\pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
